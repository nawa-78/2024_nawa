{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ac83a0a-4414-4b79-89df-5edfb2a9e900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 12:16:34.671759: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import AdamW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d99d5d0-1579-4662-a690-5e177ebef21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.30.2)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.8.17)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.4.3)\n",
      "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.7.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: fugashi in /usr/local/lib/python3.8/dist-packages (1.1.0)\n",
      "Requirement already satisfied: ipadic in /usr/local/lib/python3.8/dist-packages (1.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers datasets\n",
    "\n",
    "# 東北大学の日本語用BERT使用に必要なパッケージをインストール\n",
    "! pip install fugashi ipadic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41ee31-5fe4-44d9-bf0f-52f98a671746",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3a738c-e34a-4567-a19c-5a41e5846588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_excel(\"dialogueact_data_train.xlsx\",engine = \"openpyxl\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c1addf-6004-4b5e-b805-fb189fd8cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_excel(\"dialogueact_data_val.xlsx\",engine = \"openpyxl\")\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de7a1b-2f35-455b-8032-f222457bd834",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs1 = df_train[\"発話者\"]\n",
    "train_docs2 = df_train[\"応答者\"]\n",
    "\n",
    "train_label1= df_train[\"自己開示\"].tolist()\n",
    "train_label2 = df_train[\"質問(YesNo)\"].tolist()\n",
    "train_label3 = df_train[\"質問(What)\"].tolist()\n",
    "train_label4 = df_train[\"応答(YesNo)\"].tolist()\n",
    "train_label5 = df_train[\"応答(平叙)\"].tolist()\n",
    "train_label6 = df_train[\"あいづち\"].tolist()\n",
    "train_label7 = df_train[\"フィラー\"].tolist()\n",
    "train_label8 = df_train[\"確認\"].tolist()\n",
    "train_label9 = df_train[\"要求\"].tolist()\n",
    "#print(len(train_docs1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da1902-6fb5-4eac-8c01-a989fc253724",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = df_train[['自己開示', '質問(YesNo)', '質問(What)', '応答(YesNo)', '応答(平叙)', 'あいづち', 'フィラー', '確認', '要求']].values.tolist()\n",
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872fe58-8338-42d9-bc3c-093b5ac15aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_docs1 = df_val[\"発話者\"]\n",
    "val_docs2 = df_val[\"応答者\"]\n",
    "\n",
    "val_label1= df_val[\"自己開示\"].tolist()\n",
    "val_label2 = df_val[\"質問(YesNo)\"].tolist()\n",
    "val_label3 = df_val[\"質問(What)\"].tolist()\n",
    "val_label4 = df_val[\"応答(YesNo)\"].tolist()\n",
    "val_label5 = df_val[\"応答(平叙)\"].tolist()\n",
    "val_label6 = df_val[\"あいづち\"].tolist()\n",
    "val_label7 = df_val[\"フィラー\"].tolist()\n",
    "val_label8 = df_val[\"確認\"].tolist()\n",
    "val_label9 = df_val[\"要求\"].tolist()\n",
    "#print(len(val_docs1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b606b6e4-e572-4fa4-9751-dcc1d3745d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = df_val[['自己開示', '質問(YesNo)', '質問(What)', '応答(YesNo)', '応答(平叙)', 'あいづち', 'フィラー', '確認', '要求']].values.tolist()\n",
    "len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe3bd67-911e-454f-ade0-c0d53271c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#自己開示,質問(YesNo),質問(What),応答(YesNo),応答(平叙),あいづち,フィラー,確認,要求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9c779-39d5-4272-9126-1f30619baefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_excel(\"dialogueact_data_test.xlsx\",engine = \"openpyxl\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db41ba76-d48a-47a0-954e-1ea1d67cf6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs1 = df_test[\"発話者\"]\n",
    "test_docs2 = df_test[\"応答者\"]\n",
    "\n",
    "test_label1= df_test[\"自己開示\"].tolist()\n",
    "test_label2 = df_test[\"質問(YesNo)\"].tolist()\n",
    "test_label3 = df_test[\"質問(What)\"].tolist()\n",
    "test_label4 = df_test[\"応答(YesNo)\"].tolist()\n",
    "test_label5 = df_test[\"応答(平叙)\"].tolist()\n",
    "test_label6 = df_test[\"あいづち\"].tolist()\n",
    "test_label7 = df_test[\"フィラー\"].tolist()\n",
    "test_label8 = df_test[\"確認\"].tolist()\n",
    "test_label9 = df_test[\"要求\"].tolist()\n",
    "#print(len(train_docs1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b734179b-ddc9-4dd9-bdeb-3240e1f4b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = df_test[['自己開示', '質問(YesNo)', '質問(What)', '応答(YesNo)', '応答(平叙)', 'あいづち', 'フィラー', '確認', '要求']].values.tolist()\n",
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2576f029-2eb0-44da-943d-1bb9d3165d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "df_train[\"対話行為list\"] = train_labels\n",
    "train = pd.concat([df_train[\"発話者\"].astype(str),df_train[\"応答者\"].astype(str)], axis = 1)\n",
    "train = pd.concat([train,df_train[\"対話行為list\"]], axis = 1)\n",
    "train[\"対話行為list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fcfea7-a364-4574-ab8d-15920aa31c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.DataFrame()\n",
    "df_val[\"対話行為list\"] = val_labels\n",
    "val = pd.concat([df_val[\"発話者\"].astype(str), df_val[\"応答者\"].astype(str)], axis = 1)\n",
    "val = pd.concat([val, df_val[\"対話行為list\"]], axis = 1)\n",
    "val[\"対話行為list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567796b6-23ea-443b-9b91-e8ea49a0cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "df_test[\"対話行為list\"] = test_labels\n",
    "test = pd.concat([df_test[\"発話者\"].astype(str), df_test[\"応答者\"].astype(str)], axis = 1)\n",
    "test = pd.concat([test, df_test[\"対話行為list\"]], axis = 1)\n",
    "test[\"対話行為list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ce99c-85f9-4526-8a2c-2b0009d9990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1afbd8-d2d4-4417-921a-0dca273c2300",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e4c479-2ea1-4e70-b27a-eb995d8dfc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理関数: tokenize_function\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "def tokenize_function(batch):\n",
    "    tokenized_batch = tokenizer(batch['発話者'], batch['応答者'], truncation=True, padding='max_length')\n",
    "    #tokenized_batch['labels'] = batch['対話行為list']\n",
    "    tokenized_batch['labels'] = np.argmax(batch['対話行為list'], axis=-1)\n",
    "    return tokenized_batch\n",
    "\n",
    "# Transformers用のデータセット形式に変換\n",
    "# pandas.DataFrame -> datasets.Dataset\n",
    "target_columns = ['発話者', \"応答者\",\"対話行為list\"]\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train[target_columns])\n",
    "val_dataset = Dataset.from_pandas(val[target_columns])\n",
    "test_dataset = Dataset.from_pandas(test[target_columns])\n",
    "batch_size = 10\n",
    "# 前処理（tokenize_function） を適用\n",
    "train_tokenized_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_tokenized_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "test_tokenized_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "#train_tokenized_dataset.set_format(\"torch\")\n",
    "#test_tokenized_dataset.set_format(\"torch\")\n",
    "#print(train_tokenized_dataset[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca837f3-8a98-45a2-85ad-92abb838f9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0889afd-64ff-44f2-b973-df8fbb600c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://qiita.com/nipo/items/44ce3aaf6acd4e2649d1\n",
    "#https://qiita.com/m__k/items/2c4e476d7ac81a3a44af\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from datasets import load_metric\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "# 評価指標を定義\n",
    "# https://huggingface.co/docs/transformers/training\n",
    "#metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     label_ids = np.argmax(labels, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=label_ids)\n",
    "\n",
    "# 訓練時の設定\n",
    "# https://huggingface.co/docs/transformers/v4.21.1/en/main_classes/trainer#transformers.TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3.0,\n",
    "    learning_rate=6e-5,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    #logging_strategy=\"steps\"\n",
    "    eval_steps=500,\n",
    "    load_best_model_at_end=True\n",
    ")  # 200ステップ毎にテストデータで評価する\n",
    "\n",
    "# Trainerを生成\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized_dataset,\n",
    "    eval_dataset=val_tokenized_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# 訓練を実行\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a709a-a9e8-4f76-b6d7-b4e0add28afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0113a8-e63f-4794-92ef-ac833c6e61c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_state()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3eb5b8-e320-4650-8111-5502f8e3e526",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdialogueact_weight.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'dialogueact_weight.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "065a1182-37d6-463a-8e0b-a1a3d488f441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.44248325,  3.0888207 ,  0.2890306 , ..., -2.2671795 ,\n",
       "         5.1224165 , -2.6767426 ],\n",
       "       [ 5.5302787 ,  0.10676094,  0.51778805, ..., -2.3762167 ,\n",
       "         0.02335134, -1.4245491 ],\n",
       "       [ 5.7250667 , -0.36562467, -1.5666794 , ..., -2.7283645 ,\n",
       "         0.86325574, -1.3091459 ],\n",
       "       ...,\n",
       "       [ 6.048429  , -0.13189386, -0.850973  , ..., -2.4747353 ,\n",
       "         0.17238587, -0.35804343],\n",
       "       [-0.01138119, -2.5704849 , -2.4787784 , ...,  0.88390434,\n",
       "        -1.8324531 , -3.0438468 ],\n",
       "       [ 4.569826  , -0.76393616, -2.4801252 , ..., -2.7312508 ,\n",
       "         0.49612644, -2.5303843 ]], dtype=float32), label_ids=array([7, 0, 0, ..., 0, 3, 4]), metrics={'test_loss': 0.7614129781723022, 'test_accuracy': 0.7523219814241486, 'test_f1': 0.6225767230484366, 'test_precision': 0.6471005341050469, 'test_recall': 0.6200167194051933, 'test_runtime': 22.2661, 'test_samples_per_second': 116.051, 'test_steps_per_second': 14.506})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result = trainer.predict(test_tokenized_dataset)\n",
    "pred_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe8aca5-7b2e-4876-a07f-ae792446164f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58d96af6-de9b-4efd-ac91-a85a53550445",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_labels = ['自己開示', '質問(YesNo)', '質問(What)', '応答(YesNo)', '応答(平叙)', 'あいづち', 'フィラー', '確認', '要求']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4112026e-3bfd-4209-91ae-c93ff85e00db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_softmax(x):\n",
    "    f_x = np.exp(x) / np.sum(np.exp(x))\n",
    "    return f_x\n",
    "\n",
    "#def analyze_emotion(text, show_fig=False, ret_prob=False):\n",
    "def analyze_emotion(text1, text2):\n",
    "    # 推論モードを有効か\n",
    "    model.eval()\n",
    "\n",
    "    # 入力データ変換 + 推論\n",
    "    tokens = tokenizer(text1, text2, truncation=True, return_tensors=\"pt\")\n",
    "    tokens.to(model.device)\n",
    "    preds = model(**tokens)\n",
    "    #print(preds)\n",
    "    prob = np_softmax(preds.logits.cpu().detach().numpy()[0])\n",
    "    out_dict = {n: p for n, p in zip(dialogue_labels, prob)}\n",
    "    \n",
    "    \n",
    "\n",
    "    # 棒グラフを描画\n",
    "    #if show_fig:\n",
    "        #plt.figure(figsize=(8, 3))\n",
    "        #df = pd.DataFrame(out_dict.items(), columns=['name', 'prob'])\n",
    "        #sns.barplot(x='name', y='prob', data=df)\n",
    "        #plt.title('入力文 : ' + text, fontsize=15)\n",
    "\n",
    "    #if ret_prob:\n",
    "        #return out_dict\n",
    "    return out_dict\n",
    "\n",
    "# 動作確認\n",
    "analyze_emotion(\"そうなの！チラッと見たら全然移りが違うの。真剣な表情くっきり！\",\"Aも買っちゃえば？高いかもしれないけど\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81b14223-df77-4448-b3ef-233bdb776143",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m fig\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# y_preds = np.argmax(pred_result.predictions, axis=1)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# dk = pd.DataFrame(y_preds)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# y_test = np.array(test_tokenized_dataset[\"labels\"])\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m dk2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(y_test)\n\u001b[1;32m     10\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSelf-disclosure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion(YesNo)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion(What)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse(YesNo)\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     11\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse(Declarative)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBackchannel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Filler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfirmation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRequest\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mempathy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_confusion_matrix\u001b[39m(y_preds, y_true, labels):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "fig=plt.figure()\n",
    "\n",
    "y_preds = np.argmax(pred_result.predictions, axis=1)\n",
    "dk = pd.DataFrame(y_preds)\n",
    "y_test = np.array(test_tokenized_dataset[\"labels\"])\n",
    "dk2 = pd.DataFrame(y_test)\n",
    "labels = ['Self-disclosure', 'question(YesNo)', 'question(What)', 'response(YesNo)', \n",
    "                   'response(Declarative)', 'Backchannel', ' Filler', 'Confirmation', 'Request','empathy']\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    ax.xaxis.set_tick_params(labelsize=10)\n",
    "    ax.yaxis.set_tick_params(labelsize=10)\n",
    "\n",
    "    plt.yticks(fontsize=10)\n",
    "    \n",
    "    plt.xticks(rotation=20, fontsize = 10)\n",
    "    plt.title(\"Normalized confusion matrix\", fontsize = 10)\n",
    "    plt.show()\n",
    "    fig.savefig(f\"Normalized confusion matrix.png\")\n",
    "\n",
    "plot_confusion_matrix(y_pred, y_test, labels)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "701ef901-2f7b-4ff7-8d9b-41668dc504ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1236\n",
      "248\n",
      "121\n",
      "87\n",
      "302\n",
      "437\n",
      "60\n",
      "64\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "#data = pd.concat([dk, dk2], axis = 1)\n",
    "dk.columns = ['label']\n",
    "dk2.columns = ['label']\n",
    "print(len(dk[dk[\"label\"] == 0]))\n",
    "print(len(dk[dk[\"label\"] == 1]))\n",
    "print(len(dk[dk[\"label\"] == 2]))\n",
    "print(len(dk[dk[\"label\"] == 3]))\n",
    "print(len(dk[dk[\"label\"] == 4]))\n",
    "print(len(dk[dk[\"label\"] == 5]))\n",
    "print(len(dk[dk[\"label\"] == 6]))\n",
    "print(len(dk[dk[\"label\"] == 7]))\n",
    "print(len(dk[dk[\"label\"] == 8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f831a59-8c9a-4617-bfdb-f59ab707ed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv(\"kyoukanreituika.csv\", index = False, encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7ac14824-8208-4925-9a87-dff1ddc55522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1187\n",
      "192\n",
      "130\n",
      "97\n",
      "344\n",
      "390\n",
      "95\n",
      "128\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(dk2[dk2[\"label\"] == 0]))\n",
    "print(len(dk2[dk2[\"label\"] == 1]))\n",
    "print(len(dk2[dk2[\"label\"] == 2]))\n",
    "print(len(dk2[dk2[\"label\"] == 3]))\n",
    "print(len(dk2[dk2[\"label\"] == 4]))\n",
    "print(len(dk2[dk2[\"label\"] == 5]))\n",
    "print(len(dk2[dk2[\"label\"] == 6]))\n",
    "print(len(dk2[dk2[\"label\"] == 7]))\n",
    "print(len(dk2[dk2[\"label\"] == 8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d20d38-4edf-4bac-b748-d87487ec82e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
